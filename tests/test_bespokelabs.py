from datamax.parser.core import DataMax

# ğŸ” Replace with your actual credentials
API_KEY = "your-api-key"
BASE_URL = "https://api.openai.com/v1"
MODEL_NAME = "qwen-turbo"  # or "glm-4", "gpt-4", etc.

# ğŸ‘‡ Test content
test_prompt = "è¯·è§£é‡Šäººå·¥æ™ºèƒ½çš„åŸºæœ¬åŸç†ã€‚"
test_content = """
äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œè‡´åŠ›äºç ”ç©¶ã€å¼€å‘æ¨¡æ‹Ÿã€å»¶ä¼¸å’Œæ‰©å±•äººçš„æ™ºèƒ½çš„ç†è®ºã€æ–¹æ³•ã€æŠ€æœ¯åŠåº”ç”¨ç³»ç»Ÿã€‚
"""

# âœ… Test call_llm_with_bespokelabs (single prompt)
print("\n=== Testing: call_llm_with_bespokelabs ===")
try:
    result = DataMax.call_llm_with_bespokelabs(
        prompt=test_prompt,
        model_name=MODEL_NAME,
        api_key=API_KEY,
        base_url=BASE_URL,
    )
    print("LLM Output:\n", result)
except Exception as e:
    print("Error during LLM call:", e)


# âœ… Test qa_generator_with_bespokelabs (multiple QA chunks)
print("\n=== Testing: qa_generator_with_bespokelabs ===")
try:
    parser = DataMax()
    qa_results = parser.qa_generator_with_bespokelabs(
        content=test_content,
        model_name=MODEL_NAME,
        api_key=API_KEY,
        base_url=BASE_URL,
    )
    for i, qa in enumerate(qa_results):
        print(f"\n--- QA Chunk {i + 1} ---\n{qa}")
except Exception as e:
    print("Error during QA generation:", e)

import WechatImage from '@site/static/img/wechat.png';


# DataMax

<div align="center">

**ä¸­æ–‡** | [English](README.md)

[![PyPI version](https://badge.fury.io/py/pydatamax.svg)](https://badge.fury.io/py/pydatamax) [![Python](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/) [![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

</div>

ä¸€ä¸ªå¼ºå¤§çš„å¤šæ ¼å¼æ–‡ä»¶è§£æã€æ•°æ®æ¸…æ´—å’ŒAIæ ‡æ³¨å·¥å…·åº“ã€‚

## âœ¨ æ ¸å¿ƒç‰¹æ€§

- ğŸ”„ **å¤šæ ¼å¼æ”¯æŒ**: PDFã€DOCX/DOCã€PPT/PPTXã€XLS/XLSXã€HTMLã€EPUBã€TXTã€å›¾ç‰‡ç­‰
- ğŸ§¹ **æ™ºèƒ½æ¸…æ´—**: å¼‚å¸¸æ£€æµ‹ã€éšç§ä¿æŠ¤ã€æ–‡æœ¬è¿‡æ»¤ä¸‰å±‚æ¸…æ´—æµç¨‹
- ğŸ¤– **AIæ ‡æ³¨**: åŸºäºLLMçš„è‡ªåŠ¨æ•°æ®æ ‡æ³¨å’Œé¢„æ ‡è®°
- âš¡ **æ‰¹é‡å¤„ç†**: é«˜æ•ˆçš„å¤šæ–‡ä»¶å¹¶è¡Œå¤„ç†
- ğŸ¯ **æ˜“äºé›†æˆ**: ç®€æ´çš„APIè®¾è®¡ï¼Œå¼€ç®±å³ç”¨

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£…

```bash
pip install pydatamax
```

### åŸºç¡€ç”¨æ³•

```python
from datamax import DataMax

# è§£æå•ä¸ªæ–‡ä»¶ï¼Œé»˜è®¤ domain="Technology"
dm = DataMax(file_path="document.pdf")
data = dm.get_data()

# æ‰¹é‡å¤„ç†
dm = DataMax(file_path=["file1.docx", "file2.pdf"])
data = dm.get_data()

# æŒ‡å®šé¢†åŸŸï¼šdomain å‚æ•°æ”¯æŒé¢„ç½®é¢†åŸŸï¼ˆTechnology, Finance, Health, Education, Legal, Marketing, Sales, Entertainment, Scienceï¼‰ï¼Œä¹Ÿå¯è‡ªå®šä¹‰
dm = DataMax(file_path="report.pdf", domain="Finance")
data = dm.get_data()

# æ•°æ®æ¸…æ´—
cleaned_data = dm.clean_data(method_list=["abnormal", "private", "filter"])

# AIæ ‡æ³¨
qa_data = dm.get_pre_label(
    api_key="your-api-key",
    base_url="https://api.openai.com/v1",
    model_name="gpt-3.5-turbo"
)
```

## ğŸ“– è¯¦ç»†æ–‡æ¡£

### æ–‡ä»¶è§£æ

#### å¯é€‰å‚æ•°ï¼šdomain
æ‰€æœ‰è§£æå™¨å‡æ”¯æŒä¸€ä¸ªå¯é€‰çš„ domain: str å‚æ•°ï¼Œç”¨äºè®°å½•ä¸šåŠ¡é¢†åŸŸï¼Œé»˜è®¤å€¼ä¸º "Technology"ã€‚
é¢„ç½®é¢†åŸŸåˆ—è¡¨ï¼š["Technology","Finance","Health","Education","Legal","Marketing","Sales","Entertainment","Science"]ï¼Œä¹Ÿå¯ä»¥ä¼ å…¥ä»»æ„è‡ªå®šä¹‰å­—ç¬¦ä¸²ã€‚

#### æ”¯æŒçš„æ ¼å¼

| æ ¼å¼ | æ‰©å±•å | ç‰¹æ®ŠåŠŸèƒ½ |
|------|--------|----------|
| æ–‡æ¡£ | `.pdf`, `.docx`, `.doc` | OCRæ”¯æŒã€Markdownè½¬æ¢ |
| è¡¨æ ¼ | `.xlsx`, `.xls` | ç»“æ„åŒ–æ•°æ®æå– |
| æ¼”ç¤º | `.pptx`, `.ppt` | å¹»ç¯ç‰‡å†…å®¹æå– |
| ç½‘é¡µ | `.html`, `.epub` | æ ‡ç­¾è§£æ |
| å›¾ç‰‡ | `.jpg`, `.png`, `.jpeg` | OCRæ–‡å­—è¯†åˆ« |
| æ–‡æœ¬ | `.txt` | ç¼–ç è‡ªåŠ¨æ£€æµ‹ |

#### é«˜çº§åŠŸèƒ½

```python
# PDFé«˜çº§è§£æï¼ˆéœ€è¦MinerUï¼‰
dm = DataMax(file_path="complex.pdf", use_mineru=True)

# Wordè½¬Markdown
dm = DataMax(file_path="document.docx", to_markdown=True)

# å›¾ç‰‡OCR
dm = DataMax(file_path="image.jpg", use_mineru=True)
```

### æ‰¹å¤„ç†è§£æ
```python
# æ‰¹é‡è§£æå¤šä¸ªæ–‡ä»¶
dm = DataMax(
    file_path=["file1.pdf", "file2.docx"],
    use_mineru=True
)
data = dm.get_data()
```

### æ–‡ä»¶ç¼“å­˜
```python
# ç¼“å­˜è§£æç»“æœï¼Œé¿å…é‡å¤è§£æ
dm = DataMax(
    file_path=["file1.pdf", "file2.docx"],
    ttl=3600  # ç¼“å­˜æ—¶é—´ï¼Œå•ä½ç§’, é»˜è®¤3600ç§’, å¦‚æœä¸º0åˆ™ä¸ç¼“å­˜
)
data = dm.get_data()
```

### æ•°æ®æ¸…æ´—
## å¼‚å¸¸å¤„ç†

- remove_abnormal_chars ä»æ–‡æœ¬ä¸­ç§»é™¤å¼‚å¸¸å­—ç¬¦
- remove_html_tags ç§»é™¤HTMLæ ‡ç­¾
- convert_newlines å°†\rè½¬æ¢ä¸º\nå¹¶å°†å¤šä¸ª\nåˆå¹¶ä¸ºå•ä¸ª\n
- single_space å°†å¤šä¸ªç©ºæ ¼(2ä¸ªä»¥ä¸Š)è½¬æ¢ä¸ºå•ä¸ªç©ºæ ¼
- tabs_to_spaces å°†åˆ¶è¡¨ç¬¦è½¬æ¢ä¸º4ä¸ªç©ºæ ¼
- remove_invisible_chars ç§»é™¤ä¸å¯è§ASCIIå­—ç¬¦
- simplify_chinese å°†ç¹ä½“ä¸­æ–‡è½¬æ¢ä¸ºç®€ä½“ä¸­æ–‡

## æ–‡æœ¬è¿‡æ»¤

- filter_by_word_repetition è¯é‡å¤ç‡è¿‡æ»¤
- filter_by_char_count æŒ‰å­—ç¬¦æ•°é‡è¿‡æ»¤
- filter_by_numeric_content æŒ‰æ•°å­—å æ¯”è¿‡æ»¤

## éšç§è„±æ•

- replace_ip
- replace_email
- replace_customer_number   4008-123-123 æ¸…æ´—çƒ­çº¿ç”µè¯
- replace_bank_id
- replace_phone_number
- replace_qq
- replace_id_card


```python
# ä¸‰ç§æ¸…æ´—æ¨¡å¼(å¿«é€Ÿä½¿ç”¨ä¸æ”¯æŒè‡ªå®šä¹‰)
dm.clean_data(method_list=[
    "abnormal",  # å¼‚å¸¸æ•°æ®å¤„ç†
    "private",   # éšç§ä¿¡æ¯è„±æ•
    "filter"     # æ–‡æœ¬è¿‡æ»¤è§„èŒƒåŒ–
])

# è‡ªå®šä¹‰æ¸…æ´—æµç¨‹(æ”¯æŒè‡ªå®šä¹‰)
from datamax.utils.data_cleaner import TextFilter, PrivacyDesensitization, AbnormalCleaner
dm = DataMax(
    file_path=r"C:\Users\cykro\Desktop\é¦™æ¸¯å¼€å‘æœº.txt"
)
parsed_data = dm.get_data().get('content')
# 1. æ–‡æœ¬è¿‡æ»¤
tf = TextFilter(parsed_data=parsed_data)
    # è¯é‡å¤ç‡è¿‡æ»¤ å‚æ•° threshold é»˜è®¤ä¸º 0.6ï¼Œå³æ–‡æœ¬ä¸­æœ€å¤šå…è®¸ 60% çš„å­—ç¬¦æ˜¯é‡å¤çš„
tf_bool = tf.filter_by_word_repetition(threshold=0.6)
if tf_bool:
    print("æ–‡æœ¬é€šè¿‡è¯é‡å¤ç‡è¿‡æ»¤")
else:
    print("æ–‡æœ¬æœªé€šè¿‡è¯é‡å¤ç‡è¿‡æ»¤")
    
# æŒ‰å­—ç¬¦æ•°é‡è¿‡æ»¤ å‚æ•° min_chars é»˜è®¤ä¸º 30ï¼Œå³æ–‡æœ¬ä¸­æœ€å°‘å…è®¸ 30 ä¸ªå­—ç¬¦, max_chars é»˜è®¤ä¸º 500000ï¼Œå³æ–‡æœ¬ä¸­æœ€å¤šå…è®¸ 500000 ä¸ªå­—ç¬¦
tf_bool = tf.filter_by_char_count(min_chars=30, max_chars=500000)
if tf_bool:
    print("æ–‡æœ¬é€šè¿‡å­—ç¬¦æ•°é‡è¿‡æ»¤")
else:
    print("æ–‡æœ¬æœªé€šè¿‡å­—ç¬¦æ•°é‡è¿‡æ»¤")

# æŒ‰æ•°å­—å æ¯”è¿‡æ»¤ å‚æ•° threshold é»˜è®¤ä¸º 0.6ï¼Œå³æ–‡æœ¬ä¸­æœ€å¤šå…è®¸ 60% çš„å­—ç¬¦æ˜¯æ•°å­—
tf_bool = tf.filter_by_numeric_content(threshold=0.6)
if tf_bool:
    print("æ–‡æœ¬é€šè¿‡æ•°å­—æ¯”ä¾‹è¿‡æ»¤")
else:
print("æ–‡æœ¬æœªé€šè¿‡æ•°å­—æ¯”ä¾‹è¿‡æ»¤")

# 2. éšç§è„±æ•
pd = PrivacyDesensitization(parsed_data=parsed_data)
res = pd.replace_ip(
    token="MyIP"
)
print(res)

# 3. å¼‚å¸¸å­—ç¬¦æ¸…æ´—
ac = AbnormalCleaner(parsed_data=parsed_data)
res = ac.remove_abnormal_chars()
res = ac.remove_html_tags()
res = ac.convert_newlines()
res = ac.single_space()
res = ac.tabs_to_spaces()
res = ac.remove_invisible_chars()
res = ac.simplify_chinese()
print(res)
```

### æ–‡æœ¬åˆ‡åˆ†

```python
dm.split_data(
    chunk_size=500,      # æ–‡æœ¬å—å¤§å°
    chunk_overlap=100,    # é‡å é•¿åº¦
    use_langchain=True  # ä½¿ç”¨LangChainè¿›è¡Œæ–‡æœ¬åˆ‡åˆ†
)

# å½“use_langchainä¸ºFalseæ—¶ï¼Œä½¿ç”¨è‡ªå®šä¹‰åˆ‡åˆ†æ–¹æ³•
# ã€‚ï¼ï¼Ÿä½œä¸ºåˆ†éš”ç¬¦ï¼Œè¿ç»­çš„åˆ†éš”ç¬¦ä¼šè¢«åˆå¹¶ chunk_sizeæ˜¯ä¸¥æ ¼çš„å­—ç¬¦ä¸²é•¿åº¦ä¸ä¼šè¶…è¿‡
for chunk in parser.split_data(chunk_size=500, chunk_overlap=100, use_langchain=False).get("content"):
    print(chunk)
```

### AIæ ‡æ³¨

```python
# è‡ªå®šä¹‰æ ‡æ³¨ä»»åŠ¡
qa_data = dm.get_pre_label(
    api_key="sk-xxx",
    base_url="https://api.provider.com/v1",
    model_name="model-name",
    chunk_size=500,        # æ–‡æœ¬å—å¤§å°
    chunk_overlap=100,     # é‡å é•¿åº¦
    question_number=5,     # æ¯å—ç”Ÿæˆé—®é¢˜æ•°
    max_workers=5          # å¹¶å‘æ•°
)
# ä¿å­˜ç»“æœ
dm.save_label_data(qa_data)
```

## âš™ï¸ ç¯å¢ƒé…ç½®

### å¯é€‰ä¾èµ–

#### LibreOfficeï¼ˆDOCæ–‡ä»¶æ”¯æŒï¼‰

**Ubuntu/Debian:**
```bash
apt update && apt install -y libreoffice libreoffice-dev python3-uno
```

**Windows:**
1. ä¸‹è½½å®‰è£… [LibreOffice](https://www.libreoffice.org/download/)
2. æ·»åŠ åˆ°ç¯å¢ƒå˜é‡: `C:\Program Files\LibreOffice\program`

#### MinerUï¼ˆé«˜çº§PDFè§£æï¼‰

```bash
# 1.å®‰è£…MinerU
pip install -U "magic-pdf[full]" --extra-index-url https://wheels.myhloli.com

# 2.å®‰è£…æ¨¡å‹
python datamax/download_models.py
```

è¯¦ç»†é…ç½®è¯·å‚è€ƒ [MinerUæ–‡æ¡£](https://github.com/opendatalab/MinerU)

## ğŸ› ï¸ å¼€å‘

### æœ¬åœ°å®‰è£…

```bash
git clone https://github.com/Hi-Dolphin/datamax.git
cd datamax
pip install -r requirements.txt
python setup.py install
```

### æœ¬åœ°è°ƒè¯•

```python
import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__)))

from datamax import DataMax

# ç¤ºä¾‹ä»£ç 
dm = DataMax(file_path="test.pdf")
data = dm.get_data()
print(data)
```


## ğŸ“‹ ç³»ç»Ÿè¦æ±‚

- Python >= 3.10
- æ”¯æŒ Windowsã€macOSã€Linux

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ [MIT License](LICENSE) å¼€æºåè®®ã€‚

## ğŸ“ è”ç³»æˆ‘ä»¬

- ğŸ“§ Email: cy.kron@foxmail.com
- ğŸ› Issues: [GitHub Issues](https://github.com/Hi-Dolphin/datamax/issues)
- ğŸ“š æ–‡æ¡£: [é¡¹ç›®ä¸»é¡µ](https://github.com/Hi-Dolphin/datamax)
- ğŸ’¬ å¾®ä¿¡äº¤æµç¾¤ï¼š<br /><img src='WechatImage' width="300"/>
---

â­ å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œè¯·ç»™æˆ‘ä»¬ä¸€ä¸ªæ˜Ÿæ ‡ï¼


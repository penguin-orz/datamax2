"""
è¯­æ–™æ ‡æ³¨æ¨¡å—æµ‹è¯•

æµ‹è¯•æ‰€æœ‰labeleræ¨¡å—çš„åŠŸèƒ½ï¼Œç¡®ä¿ä»£ç å¯ä»¥æ­£å¸¸è¿è¡Œ
"""

import asyncio
import json
import os
from pathlib import Path

import pytest
from loguru import logger

from datamax.labeler import (
    BaseLabeler, LabelConfig, LabelResult,
    LLMClient, LLMConfig, TokenCounter,
    PromptManager, PromptTemplate,
    QALabeler, QAConfig, QAResult,
    TextSplitter, SplitterConfig
)


class MockLLMClient:
    """æ¨¡æ‹ŸLLMå®¢æˆ·ç«¯ï¼Œç”¨äºæµ‹è¯•"""
    
    def __init__(self):
        self.logger = logger
    
    def chat(self, messages):
        """æ¨¡æ‹ŸèŠå¤©å“åº”"""
        from datamax.labeler.llm_client import LLMResponse
        
        # æ ¹æ®æ¶ˆæ¯å†…å®¹è¿”å›ä¸åŒçš„æ¨¡æ‹Ÿå“åº”
        user_message = messages[-1].content if messages else ""
        
        if "QA" in user_message or "é—®ç­”" in user_message:
            mock_response = {
                "qa_pairs": [
                    {
                        "question": "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
                        "answer": "äººå·¥æ™ºèƒ½æ˜¯ä¸€é—¨ç ”ç©¶å¦‚ä½•è®©æœºå™¨æ¨¡æ‹Ÿäººç±»æ™ºèƒ½çš„ç§‘å­¦ã€‚",
                        "type": "factual"
                    },
                    {
                        "question": "æœºå™¨å­¦ä¹ çš„æ ¸å¿ƒæ€æƒ³æ˜¯ä»€ä¹ˆï¼Ÿ",
                        "answer": "æœºå™¨å­¦ä¹ çš„æ ¸å¿ƒæ€æƒ³æ˜¯è®©è®¡ç®—æœºé€šè¿‡æ•°æ®å­¦ä¹ è§„å¾‹ï¼Œæ— éœ€æ˜ç¡®ç¼–ç¨‹ã€‚",
                        "type": "comprehension"
                    }
                ]
            }
            content = f"```json\n{json.dumps(mock_response, ensure_ascii=False)}\n```"
        else:
            content = "è¿™æ˜¯ä¸€ä¸ªæ¨¡æ‹Ÿçš„LLMå“åº”ã€‚"
        
        return LLMResponse(
            content=content,
            usage={"prompt_tokens": 100, "completion_tokens": 50, "total_tokens": 150},
            model="mock-model",
            finish_reason="stop",
            response_time=1.0
        )
    
    def count_tokens(self, text: str) -> int:
        """æ¨¡æ‹Ÿtokenè®¡æ•°"""
        return len(text) // 4


def test_text_splitter():
    """æµ‹è¯•æ–‡æœ¬åˆ†å‰²å™¨"""
    logger.info("å¼€å§‹æµ‹è¯•æ–‡æœ¬åˆ†å‰²å™¨...")
    
    # æµ‹è¯•åŸºæœ¬åˆ†å‰²
    text = """
    äººå·¥æ™ºèƒ½ï¼ˆArtificial Intelligenceï¼Œç®€ç§°AIï¼‰æ˜¯ä¸€é—¨ç ”ç©¶å¦‚ä½•è®©æœºå™¨æ¨¡æ‹Ÿäººç±»æ™ºèƒ½çš„ç§‘å­¦ã€‚
    å®ƒåŒ…æ‹¬æœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ä¹ ã€è‡ªç„¶è¯­è¨€å¤„ç†ç­‰å¤šä¸ªåˆ†æ”¯é¢†åŸŸã€‚
    
    æœºå™¨å­¦ä¹ æ˜¯AIçš„é‡è¦ç»„æˆéƒ¨åˆ†ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯è®©è®¡ç®—æœºé€šè¿‡æ•°æ®å­¦ä¹ è§„å¾‹ï¼Œè€Œæ— éœ€æ˜ç¡®ç¼–ç¨‹ã€‚
    æ·±åº¦å­¦ä¹ åˆ™æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é›†ï¼Œå®ƒä½¿ç”¨ç¥ç»ç½‘ç»œæ¥è§£å†³å¤æ‚é—®é¢˜ã€‚
    
    è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰ä¸“æ³¨äºè®©è®¡ç®—æœºç†è§£å’Œç”Ÿæˆäººç±»è¯­è¨€ã€‚
    å®ƒåœ¨æœç´¢å¼•æ“ã€æœºå™¨ç¿»è¯‘ã€èŠå¤©æœºå™¨äººç­‰åº”ç”¨ä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚
    """
    
    # æµ‹è¯•é€’å½’åˆ†å‰²å™¨
    config = SplitterConfig(chunk_size=200, chunk_overlap=50)
    splitter = TextSplitter.create_splitter("recursive", config)
    chunks = splitter.split_text(text)
    
    assert len(chunks) > 0, "åº”è¯¥ç”Ÿæˆè‡³å°‘ä¸€ä¸ªæ–‡æœ¬å—"
    assert all(len(chunk.content) <= 250 for chunk in chunks), "æ‰€æœ‰å—çš„å¤§å°åº”è¯¥åœ¨é™åˆ¶èŒƒå›´å†…"
    
    logger.info(f"é€’å½’åˆ†å‰²å™¨æµ‹è¯•é€šè¿‡ï¼Œç”Ÿæˆäº† {len(chunks)} ä¸ªæ–‡æœ¬å—")
    
    # æµ‹è¯•è¯­ä¹‰åˆ†å‰²å™¨
    semantic_splitter = TextSplitter.create_splitter("semantic", config)
    semantic_chunks = semantic_splitter.split_text(text)
    
    assert len(semantic_chunks) > 0, "è¯­ä¹‰åˆ†å‰²å™¨åº”è¯¥ç”Ÿæˆè‡³å°‘ä¸€ä¸ªæ–‡æœ¬å—"
    
    logger.info(f"è¯­ä¹‰åˆ†å‰²å™¨æµ‹è¯•é€šè¿‡ï¼Œç”Ÿæˆäº† {len(semantic_chunks)} ä¸ªæ–‡æœ¬å—")
    
    # æµ‹è¯•å¿«é€Ÿåˆ†å‰²
    quick_chunks = TextSplitter.quick_split(text, chunk_size=150)
    assert len(quick_chunks) > 0, "å¿«é€Ÿåˆ†å‰²åº”è¯¥ç”Ÿæˆè‡³å°‘ä¸€ä¸ªæ–‡æœ¬å—"
    
    logger.info("æ–‡æœ¬åˆ†å‰²å™¨æµ‹è¯•å®Œæˆ âœ“")


def test_prompt_manager():
    """æµ‹è¯•æç¤ºè¯ç®¡ç†å™¨"""
    logger.info("å¼€å§‹æµ‹è¯•æç¤ºè¯ç®¡ç†å™¨...")
    
    # åˆ›å»ºæç¤ºè¯ç®¡ç†å™¨
    prompt_manager = PromptManager()
    
    # æµ‹è¯•è·å–é»˜è®¤æ¨¡æ¿
    qa_template = prompt_manager.get_template("qa_generation")
    assert qa_template is not None, "åº”è¯¥èƒ½è·å–QAç”Ÿæˆæ¨¡æ¿"
    assert "text" in qa_template.variables, "QAæ¨¡æ¿åº”è¯¥åŒ…å«textå˜é‡"
    
    # æµ‹è¯•æ¸²æŸ“æ¨¡æ¿
    rendered = prompt_manager.render_template(
        "qa_generation",
        text="æµ‹è¯•æ–‡æœ¬",
        num_qa=3
    )
    assert "æµ‹è¯•æ–‡æœ¬" in rendered, "æ¸²æŸ“åçš„æ–‡æœ¬åº”è¯¥åŒ…å«è¾“å…¥æ–‡æœ¬"
    assert "3" in rendered, "æ¸²æŸ“åçš„æ–‡æœ¬åº”è¯¥åŒ…å«QAæ•°é‡"
    
    # æµ‹è¯•åˆ—å‡ºæ¨¡æ¿
    templates = prompt_manager.list_templates()
    assert len(templates) > 0, "åº”è¯¥æœ‰é¢„å®šä¹‰çš„æ¨¡æ¿"
    
    qa_templates = prompt_manager.list_templates(category="qa")
    assert len(qa_templates) > 0, "åº”è¯¥æœ‰QAç±»åˆ«çš„æ¨¡æ¿"
    
    # æµ‹è¯•åˆ›å»ºè‡ªå®šä¹‰æ¨¡æ¿
    custom_template = prompt_manager.create_custom_template(
        name="test_template",
        description="æµ‹è¯•æ¨¡æ¿",
        template="è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ¨¡æ¿ï¼š{{test_var}}",
        variables=["test_var"],
        category="test"
    )
    
    assert custom_template.name == "test_template", "è‡ªå®šä¹‰æ¨¡æ¿åç§°åº”è¯¥æ­£ç¡®"
    
    # æµ‹è¯•éªŒè¯æ¨¡æ¿å˜é‡
    validation = prompt_manager.validate_template_variables(
        "test_template",
        test_var="æµ‹è¯•å€¼"
    )
    assert validation["valid"] is True, "æä¾›äº†æ‰€éœ€å˜é‡ï¼ŒéªŒè¯åº”è¯¥é€šè¿‡"
    
    logger.info("æç¤ºè¯ç®¡ç†å™¨æµ‹è¯•å®Œæˆ âœ“")


def test_token_counter():
    """æµ‹è¯•tokenè®¡æ•°å™¨"""
    logger.info("å¼€å§‹æµ‹è¯•tokenè®¡æ•°å™¨...")
    
    counter = TokenCounter()
    
    # æµ‹è¯•åŸºæœ¬è®¡æ•°
    text = "è¿™æ˜¯ä¸€æ®µæµ‹è¯•æ–‡æœ¬ï¼Œç”¨æ¥éªŒè¯tokenè®¡æ•°åŠŸèƒ½ã€‚"
    token_count = counter.count_tokens(text)
    assert token_count > 0, "tokenæ•°é‡åº”è¯¥å¤§äº0"
    
    # æµ‹è¯•æ¶ˆæ¯è®¡æ•°
    from datamax.labeler.llm_client import ChatMessage
    messages = [
        ChatMessage(role="system", content="ä½ æ˜¯ä¸€ä¸ªåŠ©æ‰‹"),
        ChatMessage(role="user", content="è¯·å›ç­”æˆ‘çš„é—®é¢˜"),
        ChatMessage(role="assistant", content="å¥½çš„ï¼Œæˆ‘ä¼šå¸®åŠ©ä½ ")
    ]
    
    total_tokens = counter.count_messages_tokens(messages)
    assert total_tokens > 0, "æ¶ˆæ¯æ€»tokenæ•°åº”è¯¥å¤§äº0"
    
    # æµ‹è¯•æˆæœ¬ä¼°ç®—
    cost_info = counter.estimate_cost(100, 50, "gpt-3.5-turbo")
    assert "total_cost" in cost_info, "æˆæœ¬ä¿¡æ¯åº”è¯¥åŒ…å«æ€»æˆæœ¬"
    assert cost_info["total_cost"] > 0, "æ€»æˆæœ¬åº”è¯¥å¤§äº0"
    
    logger.info("tokenè®¡æ•°å™¨æµ‹è¯•å®Œæˆ âœ“")


def test_qa_labeler():
    """æµ‹è¯•QAæ ‡æ³¨å™¨"""
    logger.info("å¼€å§‹æµ‹è¯•QAæ ‡æ³¨å™¨...")
    
    # åˆ›å»ºæ¨¡æ‹ŸLLMå®¢æˆ·ç«¯
    mock_client = MockLLMClient()
    
    # åˆ›å»ºQAé…ç½®
    config = QAConfig(
        chunk_size=300,
        chunk_overlap=50,
        num_qa_per_chunk=2,
        enable_filtering=True
    )
    
    # åˆ›å»ºQAæ ‡æ³¨å™¨
    qa_labeler = QALabeler(mock_client, config)
    
    # æµ‹è¯•æ–‡æœ¬
    test_text = """
    äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œæ—¨åœ¨åˆ›å»ºèƒ½å¤Ÿæ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡çš„ç³»ç»Ÿã€‚
    è¿™äº›ä»»åŠ¡åŒ…æ‹¬å­¦ä¹ ã€æ¨ç†ã€é—®é¢˜è§£å†³ã€æ„ŸçŸ¥å’Œè¯­è¨€ç†è§£ã€‚
    
    æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªé‡è¦å­é¢†åŸŸï¼Œå®ƒä½¿è®¡ç®—æœºèƒ½å¤Ÿä»æ•°æ®ä¸­å­¦ä¹ ï¼Œè€Œæ— éœ€æ˜ç¡®ç¼–ç¨‹ã€‚
    æ·±åº¦å­¦ä¹ è¿›ä¸€æ­¥æ‰©å±•äº†è¿™ä¸€æ¦‚å¿µï¼Œä½¿ç”¨ç¥ç»ç½‘ç»œæ¥è§£å†³æ›´å¤æ‚çš„é—®é¢˜ã€‚
    """
    
    # æµ‹è¯•æ–‡æœ¬æ ‡æ³¨
    results = qa_labeler.label_text(test_text)
    assert len(results) > 0, "åº”è¯¥ç”Ÿæˆè‡³å°‘ä¸€ä¸ªQAç»“æœ"
    
    for result in results:
        assert isinstance(result, QAResult), "ç»“æœåº”è¯¥æ˜¯QAResultç±»å‹"
        assert len(result.qa_pairs) > 0, "åº”è¯¥ç”Ÿæˆè‡³å°‘ä¸€ä¸ªQAå¯¹"
        
        for qa_pair in result.qa_pairs:
            assert qa_pair.question.strip(), "é—®é¢˜ä¸åº”è¯¥ä¸ºç©º"
            assert qa_pair.answer.strip(), "ç­”æ¡ˆä¸åº”è¯¥ä¸ºç©º"
    
    logger.info(f"QAæ ‡æ³¨æµ‹è¯•é€šè¿‡ï¼Œç”Ÿæˆäº† {len(results)} ä¸ªç»“æœ")
    
    # æµ‹è¯•æ‰¹é‡å¤„ç†
    texts = [test_text, "è¿™æ˜¯å¦ä¸€æ®µæµ‹è¯•æ–‡æœ¬ã€‚"]
    batch_results = qa_labeler.batch_label_texts(texts)
    assert len(batch_results) == len(texts), "æ‰¹é‡ç»“æœæ•°é‡åº”è¯¥ä¸è¾“å…¥æ–‡æœ¬æ•°é‡ä¸€è‡´"
    
    logger.info("QAæ ‡æ³¨å™¨æµ‹è¯•å®Œæˆ âœ“")


def test_integration():
    """é›†æˆæµ‹è¯•"""
    logger.info("å¼€å§‹é›†æˆæµ‹è¯•...")
    
    # åˆ›å»ºä¸´æ—¶æµ‹è¯•æ–‡ä»¶
    test_content = """
    # äººå·¥æ™ºèƒ½åŸºç¡€çŸ¥è¯†
    
    äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰æ˜¯ä¸€é—¨ç ”ç©¶å¦‚ä½•è®©æœºå™¨å…·å¤‡ç±»ä¼¼äººç±»æ™ºèƒ½çš„å­¦ç§‘ã€‚
    å®ƒåŒ…æ‹¬å¤šä¸ªé‡è¦çš„å­é¢†åŸŸï¼š
    
    ## æœºå™¨å­¦ä¹ 
    æœºå™¨å­¦ä¹ æ˜¯AIçš„æ ¸å¿ƒæŠ€æœ¯ä¹‹ä¸€ï¼Œå®ƒè®©è®¡ç®—æœºèƒ½å¤Ÿä»æ•°æ®ä¸­è‡ªåŠ¨å­¦ä¹ è§„å¾‹ã€‚
    
    ## æ·±åº¦å­¦ä¹ 
    æ·±åº¦å­¦ä¹ ä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œæ¥è§£å†³å¤æ‚é—®é¢˜ï¼Œåœ¨å›¾åƒè¯†åˆ«å’Œè‡ªç„¶è¯­è¨€å¤„ç†æ–¹é¢å–å¾—äº†çªç ´æ€§è¿›å±•ã€‚
    
    ## è‡ªç„¶è¯­è¨€å¤„ç†
    NLPæŠ€æœ¯è®©è®¡ç®—æœºèƒ½å¤Ÿç†è§£å’Œç”Ÿæˆäººç±»è¯­è¨€ï¼Œå¹¿æ³›åº”ç”¨äºæœç´¢å¼•æ“ã€ç¿»è¯‘è½¯ä»¶ç­‰ã€‚
    """
    
    test_file = Path("test_document.md")
    try:
        # å†™å…¥æµ‹è¯•æ–‡ä»¶
        with open(test_file, 'w', encoding='utf-8') as f:
            f.write(test_content)
        
        # åˆ›å»ºæ¨¡æ‹ŸLLMå®¢æˆ·ç«¯å’ŒQAæ ‡æ³¨å™¨
        mock_client = MockLLMClient()
        qa_labeler = QALabeler(mock_client)
        
        # ä»æ–‡ä»¶ç”ŸæˆQAå¯¹
        results = qa_labeler.generate_qa_from_file(str(test_file))
        assert len(results) > 0, "åº”è¯¥ä»æ–‡ä»¶ç”ŸæˆQAå¯¹"
        
        # å¯¼å‡ºæµ‹è¯•
        output_file = Path("test_qa_output.jsonl")
        try:
            qa_labeler.export_qa_dataset(results, str(output_file), "jsonl")
            assert output_file.exists(), "è¾“å‡ºæ–‡ä»¶åº”è¯¥å­˜åœ¨"
            
            # éªŒè¯è¾“å‡ºå†…å®¹
            with open(output_file, 'r', encoding='utf-8') as f:
                lines = f.readlines()
                assert len(lines) > 0, "è¾“å‡ºæ–‡ä»¶åº”è¯¥æœ‰å†…å®¹"
                
                # éªŒè¯æ¯è¡Œéƒ½æ˜¯æœ‰æ•ˆçš„JSON
                for line in lines:
                    qa_data = json.loads(line.strip())
                    assert "question" in qa_data, "æ¯ä¸ªQAå¯¹åº”è¯¥åŒ…å«é—®é¢˜"
                    assert "answer" in qa_data, "æ¯ä¸ªQAå¯¹åº”è¯¥åŒ…å«ç­”æ¡ˆ"
            
            logger.info(f"æˆåŠŸå¯¼å‡º {len(lines)} ä¸ªQAå¯¹åˆ°æ–‡ä»¶")
            
        finally:
            # æ¸…ç†è¾“å‡ºæ–‡ä»¶
            if output_file.exists():
                output_file.unlink()
    
    finally:
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        if test_file.exists():
            test_file.unlink()
    
    logger.info("é›†æˆæµ‹è¯•å®Œæˆ âœ“")


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    logger.info("ğŸš€ å¼€å§‹è¿è¡Œè¯­æ–™æ ‡æ³¨æ¨¡å—æµ‹è¯•...")
    
    try:
        # è¿è¡Œå„ä¸ªæµ‹è¯•
        test_text_splitter()
        test_prompt_manager()
        test_token_counter()
        test_qa_labeler()
        test_integration()
        
        logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼è¯­æ–™æ ‡æ³¨æ¨¡å—åŠŸèƒ½æ­£å¸¸ã€‚")
        
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        raise


if __name__ == "__main__":
    main() 
import json
import os.path
import re
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path
from typing import Optional, List, Any
import uuid

import requests
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import UnstructuredMarkdownLoader
from loguru import logger
from pyexpat.errors import messages
from tqdm import tqdm  
from dotenv import load_dotenv
from datamax.utils.domain_tree import DomainTree   #for cache domain tree

lock = threading.Lock()

# ====== API settings======
# set your api key and base url in .env file
API_KEY = os.getenv("DASHSCOPE_API_KEY", "your-api-key-here")
BASE_URL = os.getenv("DASHSCOPE_BASE_URL")

def complete_api_url(base_url: str) -> str:
    """
    Normalize the given base_url so that it ends with the OpenAI-style
    chat completions endpoint.
    E.g. if user passes "https://api.provider.com/v1" it will become
    "https://api.provider.com/v1/chat/completions".
    """
    url = base_url.rstrip("/")
    # å¦‚æœè¿˜æ²¡ä»¥ /chat/completions ç»“å°¾ï¼Œå°±è‡ªåŠ¨æ‹¼ä¸Š
    if not url.endswith("/chat/completions"):
        url = f"{url}/chat/completions"
    return url

# ------------prompt-----------------
def get_system_prompt_for_match_label(tags_json, question):
    system_prompt = f"""
    # Role: æ ‡ç­¾åŒ¹é…ä¸“å®¶
    - Description: ä½ æ˜¯ä¸€åæ ‡ç­¾åŒ¹é…ä¸“å®¶ï¼Œæ“…é•¿æ ¹æ®ç»™å®šçš„æ ‡ç­¾æ•°ç»„å’Œé—®é¢˜æ•°ç»„ï¼Œå°†é—®é¢˜æ‰“ä¸Šæœ€åˆé€‚çš„é¢†åŸŸæ ‡ç­¾ã€‚ä½ ç†Ÿæ‚‰æ ‡ç­¾çš„å±‚çº§ç»“æ„ï¼Œå¹¶èƒ½æ ¹æ®é—®é¢˜çš„å†…å®¹ä¼˜å…ˆåŒ¹é…äºŒçº§æ ‡ç­¾ï¼Œè‹¥æ— æ³•åŒ¹é…åˆ™åŒ¹é…ä¸€çº§æ ‡ç­¾ï¼Œè‹¥æ— æ³•åŒ¹é…æœ€åæ‰“ä¸Š"å…¶ä»–"æ ‡ç­¾ã€‚

    ### Skill:
    1. ç†Ÿæ‚‰æ ‡ç­¾å±‚çº§ç»“æ„ï¼Œèƒ½å¤Ÿå‡†ç¡®è¯†åˆ«ä¸€çº§å’ŒäºŒçº§æ ‡ç­¾ã€‚
    2. èƒ½å¤Ÿæ ¹æ®é—®é¢˜çš„å†…å®¹ï¼Œæ™ºèƒ½åŒ¹é…æœ€åˆé€‚çš„æ ‡ç­¾ã€‚
    3. èƒ½å¤Ÿå¤„ç†å¤æ‚çš„æ ‡ç­¾åŒ¹é…é€»è¾‘ï¼Œç¡®ä¿æ¯ä¸ªé—®é¢˜éƒ½èƒ½è¢«æ‰“ä¸Šæ­£ç¡®çš„æ ‡ç­¾ã€‚
    4. èƒ½å¤ŸæŒ‰ç…§è§„å®šçš„è¾“å‡ºæ ¼å¼ç”Ÿæˆç»“æœï¼Œç¡®ä¿ä¸æ”¹å˜åŸæœ‰æ•°æ®ç»“æ„ã€‚
    5. èƒ½å¤Ÿå¤„ç†å¤§è§„æ¨¡æ•°æ®ï¼Œç¡®ä¿é«˜æ•ˆå‡†ç¡®çš„æ ‡ç­¾åŒ¹é…ã€‚

    ## Goals:
    1. å°†é—®é¢˜æ•°ç»„ä¸­çš„æ¯ä¸ªé—®é¢˜æ‰“ä¸Šæœ€åˆé€‚çš„é¢†åŸŸæ ‡ç­¾ã€‚
    2. ä¼˜å…ˆåŒ¹é…äºŒçº§æ ‡ç­¾ï¼Œè‹¥æ— æ³•åŒ¹é…åˆ™åŒ¹é…ä¸€çº§æ ‡ç­¾ï¼Œæœ€åæ‰“ä¸Š"å…¶ä»–"æ ‡ç­¾ã€‚
    3. ç¡®ä¿è¾“å‡ºæ ¼å¼ç¬¦åˆè¦æ±‚ï¼Œä¸æ”¹å˜åŸæœ‰æ•°æ®ç»“æ„ã€‚
    4. æä¾›é«˜æ•ˆçš„æ ‡ç­¾åŒ¹é…ç®—æ³•ï¼Œç¡®ä¿å¤„ç†å¤§è§„æ¨¡æ•°æ®æ—¶çš„æ€§èƒ½ã€‚
    5. ç¡®ä¿æ ‡ç­¾åŒ¹é…çš„å‡†ç¡®æ€§å’Œä¸€è‡´æ€§ã€‚

    ## OutputFormat:
    1. è¾“å‡ºç»“æœå¿…é¡»æ˜¯ä¸€ä¸ªæ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« questionã€å’Œ label å­—æ®µã€‚
    2. label å­—æ®µå¿…é¡»æ˜¯æ ¹æ®æ ‡ç­¾æ•°ç»„åŒ¹é…åˆ°çš„æ ‡ç­¾ï¼Œè‹¥æ— æ³•åŒ¹é…åˆ™æ‰“ä¸Š"å…¶ä»–"æ ‡ç­¾ã€‚
    3. ä¸æ”¹å˜åŸæœ‰æ•°æ®ç»“æ„ï¼Œåªæ–°å¢ label å­—æ®µã€‚

    ## æ ‡ç­¾jsonï¼š

    ${tags_json}

    ## é—®é¢˜æ•°ç»„ï¼š

    ${question}


    ## Workflow:
    1. Take a deep breath and work on this problem step-by-step.
    2. é¦–å…ˆï¼Œä»”ç»†åˆ†ææ¯ä¸ªé—®é¢˜çš„æ ¸å¿ƒå†…å®¹å’Œå…³é”®è¯ã€‚
    3. ç„¶åï¼Œéå†é—®é¢˜æ•°ç»„ä¸­çš„æ¯ä¸ªé—®é¢˜ï¼Œæ ¹æ®é—®é¢˜çš„å†…å®¹åŒ¹é…æ ‡ç­¾æ•°ç»„ä¸­çš„æ ‡ç­¾ã€‚
    4. ä¼˜å…ˆåŒ¹é…äºŒçº§æ ‡ç­¾ï¼Œè‹¥æ— æ³•åŒ¹é…åˆ™åŒ¹é…ä¸€çº§æ ‡ç­¾ï¼Œæœ€åæ‰“ä¸Š"å…¶ä»–"æ ‡ç­¾ã€‚
    5. å°†åŒ¹é…åˆ°çš„æ ‡ç­¾æ·»åŠ åˆ°é—®é¢˜å¯¹è±¡ä¸­ï¼Œç¡®ä¿ä¸æ”¹å˜åŸæœ‰æ•°æ®ç»“æ„ã€‚
    6. æœ€åï¼Œè¾“å‡ºç»“æœæ•°ç»„ï¼Œç¡®ä¿æ ¼å¼ç¬¦åˆè¦æ±‚ã€‚


    ## Constrains:
    1. åªæ–°å¢ä¸€ä¸ª label å­—æ®µï¼Œä¸æ”¹å˜å…¶ä»–ä»»ä½•æ ¼å¼å’Œæ•°æ®ã€‚
    2. å¿…é¡»æŒ‰ç…§è§„å®šæ ¼å¼è¿”å›ç»“æœã€‚
    3. ä¼˜å…ˆåŒ¹é…äºŒçº§æ ‡ç­¾ï¼Œè‹¥æ— æ³•åŒ¹é…åˆ™åŒ¹é…ä¸€çº§æ ‡ç­¾ï¼Œæœ€åæ‰“ä¸Š"å…¶ä»–"æ ‡ç­¾ã€‚å°½é‡ä¸åŒ¹é…"å…¶ä»–"æ ‡ç­¾ã€‚
    4. ç¡®ä¿æ ‡ç­¾åŒ¹é…çš„å‡†ç¡®æ€§å’Œä¸€è‡´æ€§ã€‚
    5. åŒ¹é…çš„æ ‡ç­¾å¿…é¡»æ¥è‡ªæ ‡ç­¾æ•°ç»„ï¼Œå¦‚æœæ— æ³•åŒ¹é…ä»»ä½•æ ‡ç­¾ï¼Œå°±æ‰“ä¸Š"å…¶ä»–"æ ‡ç­¾ã€‚
    6. è¾“å‡ºç»“æœå¿…é¡»æ˜¯ä¸€ä¸ªæ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« questionã€label å­—æ®µï¼ˆåªè¾“å‡ºè¿™ä¸ªï¼Œä¸è¦è¾“å‡ºä»»ä½•å…¶ä»–æ— å…³å†…å®¹ï¼‰ã€‚
    7. ä»”ç»†åˆ†æé—®é¢˜å†…å®¹ï¼Œå¯»æ‰¾ä¸æ ‡ç­¾çš„è¯­ä¹‰å…³è”ã€‚
    8. å¦‚æœé—®é¢˜å†…å®¹ä¸å¤šä¸ªæ ‡ç­¾ç›¸å…³ï¼Œé€‰æ‹©æœ€åŒ¹é…çš„ä¸€ä¸ªã€‚
    9. è€ƒè™‘é—®é¢˜çš„æ ¸å¿ƒä¸»é¢˜å’Œå…³é”®è¯ï¼Œè¿›è¡Œç²¾ç¡®åŒ¹é…ã€‚

    ## Output Example:
    ```json
        [
            {{
                "question": "XSSä¸ºä»€ä¹ˆä¼šåœ¨2003å¹´åå¼•èµ·äººä»¬æ›´å¤šå…³æ³¨å¹¶è¢«OWASPåˆ—ä¸ºå¨èƒæ¦œé¦–ï¼Ÿ",
                "label": "2.2 XSSæ”»å‡»"
            }},
            {{
                "question": "è¿™ä¸ªé—®é¢˜ä¸ç°æœ‰æ ‡ç­¾éƒ½ä¸ç›¸å…³",
                "label": "å…¶ä»–"
            }}
        ]
    ```
    """
    return system_prompt


def get_system_prompt_for_domain_tree(text):
    """Generate system prompt for domain tree task"""
    system_prompt = f"""
        #  Role: é¢†åŸŸåˆ†ç±»ä¸“å®¶ & çŸ¥è¯†å›¾è°±ä¸“å®¶
        - Description:
        ä½œä¸ºä¸€åèµ„æ·±çš„é¢†åŸŸåˆ†ç±»ä¸“å®¶å’ŒçŸ¥è¯†å›¾è°±ä¸“å®¶ï¼Œæ“…é•¿ä»æ–‡æœ¬å†…å®¹ä¸­æå–æ ¸å¿ƒä¸»é¢˜ï¼Œæ„å»ºåˆ†ç±»ä½“ç³»ï¼Œ
        å¹¶è¾“å‡ºè§„å®š JSON æ ¼å¼çš„æ ‡ç­¾æ ‘ã€‚

        ## Skills:
        1. ç²¾é€šæ–‡æœ¬ä¸»é¢˜åˆ†æå’Œå…³é”®è¯æå–
        2. æ“…é•¿æ„å»ºåˆ†å±‚çŸ¥è¯†ä½“ç³»
        3. ç†Ÿç»ƒæŒæ¡é¢†åŸŸåˆ†ç±»æ–¹æ³•è®º
        4. å…·å¤‡çŸ¥è¯†å›¾è°±æ„å»ºèƒ½åŠ›
        5. ç²¾é€šJSONæ•°æ®ç»“æ„

        ## Goals:
        1. åˆ†æä¹¦ç±ç›®å½•å†…å®¹
        2. è¯†åˆ«æ ¸å¿ƒä¸»é¢˜å’Œå…³é”®é¢†åŸŸ
        3. æ„å»ºä¸¤çº§åˆ†ç±»ä½“ç³»
        4. ç¡®ä¿åˆ†ç±»é€»è¾‘åˆç†
        5. ç”Ÿæˆè§„èŒƒçš„JSONè¾“å‡º

        ## Workflow:
        1. ä»”ç»†é˜…è¯»å®Œæ•´çš„ä¹¦ç±ç›®å½•å†…å®¹
        2. æå–å…³é”®ä¸»é¢˜å’Œæ ¸å¿ƒæ¦‚å¿µ
        3. å¯¹ä¸»é¢˜è¿›è¡Œåˆ†ç»„å’Œå½’ç±»
        4. æ„å»ºä¸€çº§é¢†åŸŸæ ‡ç­¾
        5. ä¸ºé€‚å½“çš„ä¸€çº§æ ‡ç­¾æ·»åŠ äºŒçº§æ ‡ç­¾
        6. æ£€æŸ¥åˆ†ç±»é€»è¾‘çš„åˆç†æ€§
        7. ç”Ÿæˆç¬¦åˆæ ¼å¼çš„JSONè¾“å‡º
        

        ## éœ€è¦åˆ†æçš„ç›®å½•
        ${text}

        ## é™åˆ¶
        1. ä¸€çº§é¢†åŸŸæ ‡ç­¾æ•°é‡5-10ä¸ª
        2. äºŒçº§é¢†åŸŸæ ‡ç­¾æ•°é‡1-10ä¸ª
        3. æœ€å¤šä¸¤å±‚åˆ†ç±»å±‚çº§
        4. åˆ†ç±»å¿…é¡»ä¸åŸå§‹ç›®å½•å†…å®¹ç›¸å…³
        5. è¾“å‡ºå¿…é¡»ç¬¦åˆæŒ‡å®š JSON æ ¼å¼ï¼Œä¸è¦è¾“å‡º JSON å¤–å…¶ä»–ä»»ä½•ä¸ç›¸å…³å†…å®¹
        6. æ ‡ç­¾çš„åå­—æœ€å¤šä¸è¦è¶…è¿‡ 6 ä¸ªå­—
        7. åœ¨æ¯ä¸ªæ ‡ç­¾å‰åŠ å…¥åºå·ï¼ˆåºå·ä¸è®¡å…¥å­—æ•°ï¼‰

        ## OutputFormat:
        ```json
        [
            {{
                "label": "1 ä¸€çº§é¢†åŸŸæ ‡ç­¾",
                "child": [
                    {{"label": "1.1 äºŒçº§é¢†åŸŸæ ‡ç­¾1"}},
                    {{"label": "1.2 äºŒçº§é¢†åŸŸæ ‡ç­¾2"}}
                ]
            }},
            {{
                "label": "2 ä¸€çº§é¢†åŸŸæ ‡ç­¾(æ— å­æ ‡ç­¾)"
            }}
        ]
        ```
    """
    return system_prompt

def get_system_prompt_for_question(query_text, question_number):
    """Generate system prompt for question generation task"""
    system_prompt = f"""
        # è§’è‰²ä½¿å‘½
        ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ–‡æœ¬åˆ†æä¸“å®¶ï¼Œæ“…é•¿ä»å¤æ‚æ–‡æœ¬ä¸­æå–å…³é”®ä¿¡æ¯å¹¶ç”Ÿæˆå¯ç”¨äºæ¨¡å‹å¾®è°ƒçš„ç»“æ„åŒ–æ•°æ®ï¼ˆä»…ç”Ÿæˆé—®é¢˜ï¼‰ã€‚

        ## æ ¸å¿ƒä»»åŠ¡
        æ ¹æ®ç”¨æˆ·æä¾›çš„æ–‡æœ¬ï¼Œç”Ÿæˆä¸å°‘äº ${question_number} ä¸ªé«˜è´¨é‡é—®é¢˜ã€‚

        ## çº¦æŸæ¡ä»¶ï¼ˆé‡è¦ï¼ï¼‰
        - å¿…é¡»åŸºäºæ–‡æœ¬å†…å®¹ç›´æ¥ç”Ÿæˆ
        - é—®é¢˜åº”å…·æœ‰æ˜ç¡®ç­”æ¡ˆæŒ‡å‘æ€§
        - éœ€è¦†ç›–æ–‡æœ¬çš„ä¸åŒæ–¹é¢
        - ç¦æ­¢ç”Ÿæˆå‡è®¾æ€§ã€é‡å¤æˆ–ç›¸ä¼¼é—®é¢˜
        - ç¡®ä¿ç”Ÿæˆå¾—å®Œæ•´æ€§

        ## å¤„ç†æµç¨‹
        1. ã€æ–‡æœ¬è§£æã€‘åˆ†æ®µå¤„ç†å†…å®¹ï¼Œè¯†åˆ«å…³é”®å®ä½“å’Œæ ¸å¿ƒæ¦‚å¿µ
        2. ã€é—®é¢˜ç”Ÿæˆã€‘åŸºäºä¿¡æ¯å¯†åº¦é€‰æ‹©æœ€ä½³æé—®ç‚¹
        3. ã€è´¨é‡æ£€æŸ¥ã€‘ç¡®ä¿ï¼š
           - é—®é¢˜ç­”æ¡ˆå¯åœ¨åŸæ–‡ä¸­æ‰¾åˆ°ä¾æ®
           - æ ‡ç­¾ä¸é—®é¢˜å†…å®¹å¼ºç›¸å…³
           - æ— æ ¼å¼é”™è¯¯

        ## è¾“å‡ºæ ¼å¼
         - JSON æ•°ç»„æ ¼å¼å¿…é¡»æ­£ç¡®
        - å­—æ®µåä½¿ç”¨è‹±æ–‡åŒå¼•å·
        - è¾“å‡ºçš„ JSON æ•°ç»„å¿…é¡»ä¸¥æ ¼ç¬¦åˆä»¥ä¸‹ç»“æ„ï¼š
        ```json
        ["é—®é¢˜1", "é—®é¢˜2", "..."]
        ```

        ## è¾“å‡ºç¤ºä¾‹
        ```json
        [ "äººå·¥æ™ºèƒ½ä¼¦ç†æ¡†æ¶åº”åŒ…å«å“ªäº›æ ¸å¿ƒè¦ç´ ï¼Ÿ","æ°‘æ³•å…¸å¯¹ä¸ªäººæ•°æ®ä¿æŠ¤æœ‰å“ªäº›æ–°è§„å®šï¼Ÿ"]
        ```

        ## å¾…å¤„ç†æ–‡æœ¬
        ${query_text}

        ## é™åˆ¶
        - å¿…é¡»æŒ‰ç…§è§„å®šçš„ JSON æ ¼å¼è¾“å‡ºï¼Œä¸è¦è¾“å‡ºä»»ä½•å…¶ä»–ä¸ç›¸å…³å†…å®¹
        - ç”Ÿæˆä¸å°‘äº${question_number}ä¸ªé«˜è´¨é‡é—®é¢˜
        - é—®é¢˜ä¸è¦å’Œææ–™æœ¬èº«ç›¸å…³ï¼Œä¾‹å¦‚ç¦æ­¢å‡ºç°ä½œè€…ã€ç« èŠ‚ã€ç›®å½•ç­‰ç›¸å…³é—®é¢˜
        - é—®é¢˜ä¸å¾—åŒ…å«ã€æŠ¥å‘Šã€æ–‡ç« ã€æ–‡çŒ®ã€è¡¨æ ¼ã€‘ä¸­æåˆ°çš„è¿™ç§è¯æœ¯ï¼Œå¿…é¡»æ˜¯ä¸€ä¸ªè‡ªç„¶çš„é—®é¢˜
    """
    return system_prompt


def get_system_prompt_for_answer(text, query_question):
    """Generate system prompt for answer generation task"""
    system_prompt = f"""
        # Role: å¾®è°ƒæ•°æ®é›†ç”Ÿæˆä¸“å®¶
        ## Profile:
        - Description: ä½ æ˜¯ä¸€åå¾®è°ƒæ•°æ®é›†ç”Ÿæˆä¸“å®¶ï¼Œæ“…é•¿ä»ç»™å®šçš„å†…å®¹ä¸­ç”Ÿæˆå‡†ç¡®çš„é—®é¢˜ç­”æ¡ˆï¼Œç¡®ä¿ç­”æ¡ˆçš„å‡†ç¡®æ€§å’Œç›¸å…³æ€§ï¼Œä½ è¦ç›´æ¥å›ç­”ç”¨æˆ·é—®é¢˜ï¼Œæ‰€æœ‰ä¿¡æ¯å·²å†…åŒ–ä¸ºä½ çš„ä¸“ä¸šçŸ¥è¯†ã€‚

        ## Skills   :
        1. ç­”æ¡ˆå¿…é¡»åŸºäºç»™å®šçš„å†…å®¹
        2. ç­”æ¡ˆå¿…é¡»å‡†ç¡®ï¼Œä¸èƒ½èƒ¡ç¼–ä¹±é€ 
        3. ç­”æ¡ˆå¿…é¡»ä¸é—®é¢˜ç›¸å…³
        4. ç­”æ¡ˆå¿…é¡»ç¬¦åˆé€»è¾‘
        5. åŸºäºç»™å®šå‚è€ƒå†…å®¹ï¼Œç”¨è‡ªç„¶æµç•…çš„è¯­è¨€æ•´åˆæˆä¸€ä¸ªå®Œæ•´ç­”æ¡ˆï¼Œä¸éœ€è¦æåŠæ–‡çŒ®æ¥æºæˆ–å¼•ç”¨æ ‡è®°

        ## Workflow:
        1. Take a deep breath and work on this problem step-by-step.
        2. é¦–å…ˆï¼Œåˆ†æç»™å®šçš„æ–‡ä»¶å†…å®¹
        3. ç„¶åï¼Œä»å†…å®¹ä¸­æå–å…³é”®ä¿¡æ¯
        4. æ¥ç€ï¼Œç”Ÿæˆä¸é—®é¢˜ç›¸å…³çš„å‡†ç¡®ç­”æ¡ˆ
        5. æœ€åï¼Œç¡®ä¿ç­”æ¡ˆçš„å‡†ç¡®æ€§å’Œç›¸å…³æ€§

        ## å‚è€ƒå†…å®¹ï¼š
        ${text}

        ## é—®é¢˜
        ${query_question}

        ## Constrains:
        1. ç­”æ¡ˆå¿…é¡»åŸºäºç»™å®šçš„å†…å®¹
        2. ç­”æ¡ˆå¿…é¡»å‡†ç¡®ï¼Œå¿…é¡»ä¸é—®é¢˜ç›¸å…³ï¼Œä¸èƒ½èƒ¡ç¼–ä¹±é€ 
        3. ç­”æ¡ˆå¿…é¡»å……åˆ†ã€è¯¦ç»†ã€åŒ…å«æ‰€æœ‰å¿…è¦çš„ä¿¡æ¯ã€é€‚åˆå¾®è°ƒå¤§æ¨¡å‹è®­ç»ƒä½¿ç”¨
        4. ç­”æ¡ˆä¸­ä¸å¾—å‡ºç° ' å‚è€ƒ / ä¾æ® / æ–‡çŒ®ä¸­æåˆ° ' ç­‰ä»»ä½•å¼•ç”¨æ€§è¡¨è¿°ï¼Œåªéœ€å‘ˆç°æœ€ç»ˆç»“æœ
    """
    return system_prompt


# ------------spliter----------------
def load_and_split_markdown(md_path: str, chunk_size: int, chunk_overlap: int) -> list:
    """
    Parse Markdown using UnstructuredMarkdownLoader
    Chunking strategy that preserves original paragraph structure

    Args:
        md_path: Path to the markdown file
        chunk_size: Size of each chunk
        chunk_overlap: Overlap between chunks

    Returns:
        List of document chunks
    """
    try:
        # Use LangChain's MarkdownLoader to load Markdown file
        logger.info(f"å¼€å§‹åˆ‡åˆ†markdownæ–‡ä»¶...")
        loader = UnstructuredMarkdownLoader(md_path)
        documents = loader.load()
        # Further split documents if needed
        splitter = RecursiveCharacterTextSplitter(
            chunk_size=chunk_size,
            chunk_overlap=chunk_overlap,
            length_function=len,
            is_separator_regex=False,
        )

        pages = splitter.split_documents(documents)
        page_content = [i.page_content for i in pages]
        logger.info(f"markdownè¢«åˆ†è§£äº†{len(page_content)}ä¸ªchunk")
        return page_content


    except Exception as e:
        logger.error(f"åŠ è½½ {Path(md_path).name} å¤±è´¥: {str(e)}")
        return []


def load_and_split_text(file_path: str, chunk_size: int, chunk_overlap: int) -> list:
    """
    Parse other formats to markdown and split
    
    Args:
        file_path: Path to the markdown file
        chunk_size: Size of each chunk
        chunk_overlap: Overlap between chunks
        
    Returns:
        List of document chunks
    """
    try:
        from datamax.parser.core import DataMax
        
        logger.info(f"å¼€å§‹å¤„ç†æ–‡ä»¶: {file_path}")
        
        # ä½¿ç”¨DataMaxè§£ææ–‡ä»¶ï¼Œè‡ªåŠ¨è½¬æ¢ä¸ºmarkdownæ ¼å¼
        dm = DataMax(file_path=file_path, to_markdown=True)
        parsed_data = dm.get_data()
        
        if not parsed_data:
            logger.error(f"æ–‡ä»¶è§£æå¤±è´¥: {file_path}")
            return []
            
        # è·å–è§£æåçš„å†…å®¹
        if isinstance(parsed_data, list):
            # å¦‚æœæ˜¯å¤šä¸ªæ–‡ä»¶ï¼Œå–ç¬¬ä¸€ä¸ª
            content = parsed_data[0].get('content', '')
        else:
            content = parsed_data.get('content', '')
            
        if not content:
            logger.error(f"æ–‡ä»¶å†…å®¹ä¸ºç©º: {file_path}")
            return []
            
        # ä½¿ç”¨LangChainçš„æ–‡æœ¬åˆ†å‰²å™¨è¿›è¡Œåˆ‡åˆ†
        splitter = RecursiveCharacterTextSplitter(
            chunk_size=chunk_size,
            chunk_overlap=chunk_overlap,
            length_function=len,
            is_separator_regex=False,
        )
        
        # ç›´æ¥åˆ†å‰²æ–‡æœ¬å†…å®¹
        page_content = splitter.split_text(content)
        logger.info(f"æ–‡ä»¶è¢«åˆ†è§£äº†{len(page_content)}ä¸ªchunk")
        return page_content
        
    except Exception as e:
        logger.error(f"å¤„ç†æ–‡ä»¶ {Path(file_path).name} å¤±è´¥: {str(e)}")
        return []


# ------------llm generator-------------------
def extract_json_from_llm_output(output: str):
    """
    Extract JSON content from LLM output, handling multiple possible formats

    Args:
        output: Raw output string from LLM

    Returns:
        Parsed JSON list if successful, None otherwise
    """
    # Try to parse the entire output directly
    try:
        return json.loads(output)
    except json.JSONDecodeError:
        pass

    # Try to extract content wrapped in ```json ```
    json_match = re.search(r"```json\n([\s\S]*?)\n```", output)
    if json_match:
        try:
            return json.loads(json_match.group(1))
        except json.JSONDecodeError as e:
            print(f"è§£æ JSON æ—¶å‡ºé”™: {e}")

    # Try to extract the most JSON-like part
    json_start = output.find("[")
    json_end = output.rfind("]") + 1
    if json_start != -1 and json_end != 0:
        try:
            return json.loads(output[json_start:json_end])
        except json.JSONDecodeError:
            pass

    logger.error(f"æ¨¡å‹æœªæŒ‰æ ‡å‡†æ ¼å¼è¾“å‡º: {output}")
    return None


def llm_generator(
    api_key: str,
    model: str,
    base_url: str,
    prompt: str,
    type: str,
    message: list = None,
    temperature: float = 0.7,
    top_p: float = 0.9,
) -> list:
    """Generate content using LLM API"""
    try:
        if not message:
            message = [
                {"role": "system", "content": prompt},
                {"role": "user", "content": "è¯·ä¸¥æ ¼æŒ‰ç…§è¦æ±‚ç”Ÿæˆå†…å®¹"},
            ]
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json",
        }
        data = {
            "model": model,
            "messages": message,
            "temperature": temperature,
            "top_p": top_p,
        }

        response = requests.post(base_url, headers=headers, json=data, timeout=120)
        response.raise_for_status()
        result = response.json()

        # Parse LLM response
        if "choices" in result and len(result["choices"]) > 0:
            output = result["choices"][0]["message"]["content"]
            if type == "question":
                fmt_output = extract_json_from_llm_output(output)
                return fmt_output if fmt_output is not None else []
            else:
                return [output] if output else []
        return []

    except Exception as e:
        print(f"LLMæå–å…³é”®è¯å¤±è´¥: {e}")
        if hasattr(e, "__traceback__") and e.__traceback__ is not None:
            print(f"é”™è¯¯è¡Œå·: {e.__traceback__.tb_lineno}")
        return []


# ------------thread_process-------------
def process_match_tags(
    api_key: str,
    model: str,
    base_url: str,
    questions: list,
    tags_json: list,
    temperature: float = 0.7,
    top_p: float = 0.9,
    max_workers: int = 3
):
    from concurrent.futures import ThreadPoolExecutor, as_completed
    logger.info(f"å¼€å§‹å¹¶å‘ç”Ÿæˆé—®é¢˜åŒ¹é…æ ‡ç­¾... (max_workers={max_workers})")
    results = []
    def match_one_question(q):
        prompt = get_system_prompt_for_match_label(tags_json, [q])
        match = llm_generator(
            api_key=api_key,
            model=model,
            base_url=base_url,
            prompt=prompt,
            type="question",
        )
        # llm_generator return a list, only one question is passed, take the first one
        return match[0] if match else {"question": q, "label": "å…¶ä»–"}

    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_q = {executor.submit(match_one_question, q): q for q in questions}
        for future in as_completed(future_to_q):
            res = future.result()
            #print(f"é—®é¢˜: {res.get('question', '')} | åŒ¹é…æ ‡ç­¾: {res.get('label', '')}")
            results.append(res)
    logger.success(f"é—®é¢˜åŒ¹é…æ ‡ç­¾ç”ŸæˆæˆåŠŸ, å…±ç”Ÿæˆ {len(results)} ä¸ªé—®é¢˜")
    return results



def process_domain_tree(
    api_key: str,
    model: str,
    base_url: str,
    text: str,
    temperature: float = 0.7,
    top_p: float = 0.9,
) -> DomainTree:
    prompt = get_system_prompt_for_domain_tree(text)

    logger.info(f"é¢†åŸŸæ ‘ç”Ÿæˆå¼€å§‹...")

    message = [
        {"role": "system", "content": prompt},
        {"role": "user", "content": "è¯·ä¸¥æ ¼æŒ‰ç…§è¦æ±‚ç”Ÿæˆå†…å®¹"},
    ]

    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
    }
    data = {
        "model": model,
        "messages": message,
        "temperature": temperature,
        "top_p": top_p,
    }
    response = requests.post(base_url, headers=headers, json=data)
    response.raise_for_status()
    result = response.json()

    # Parse LLM response
    if "choices" in result and len(result["choices"]) > 0:
        output = result["choices"][0]["message"]["content"]
        # save result
        if output:
            json_output = extract_json_from_llm_output(output)
            if json_output is not None:
                domain_tree = DomainTree()
                domain_tree.from_json(json_output)
                logger.info(f"é¢†åŸŸæ ‘ç”ŸæˆæˆåŠŸ, å…±ç”Ÿæˆ {len(json_output)} ä¸ªå¤§æ ‡ç­¾")
                return domain_tree
    return DomainTree([])


def process_questions(
    api_key: str,
    model: str,
    base_url: str,
    page_content: list,
    question_number: int,
    max_workers: int = 5,
    message: list = None,
) -> list:
    """Generate questions using multi-threading"""
    total_questions = []


    def _generate_questions(page, message):
        """Inner function for question generation"""
        prompt = get_system_prompt_for_question(page, question_number)
        if not message:
            message = [
                {"role": "system", "content": prompt},
                {"role": "user", "content": "è¯·ä¸¥æ ¼æŒ‰ç…§è¦æ±‚ç”Ÿæˆå†…å®¹"},
            ]

        questions = llm_generator(
            api_key=api_key,
            model=model,
            base_url=base_url,
            message=message,
            prompt=prompt,
            type="question",
        )
        return [{"question": question, "page": page} for question in questions] if questions else []

    logger.info(f"å¼€å§‹ç”Ÿæˆé—®é¢˜ (çº¿ç¨‹æ•°: {max_workers})...")
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = [executor.submit(_generate_questions, page, message) for page in page_content]


        with tqdm(as_completed(futures), total=len(futures), desc="ç”Ÿæˆé—®é¢˜") as pbar:
            for future in pbar:
                result = future.result()
                if result:
                    with lock:
                        total_questions.extend(result)
                    pbar.set_postfix({"å·²ç”Ÿæˆé—®é¢˜": len(total_questions)})

    return total_questions


def process_answers(
    api_key: str,
    model: str,
    base_url: str,
    question_items: list,
    message: Optional[list] = None,
    max_workers=5,
) -> dict:
    """Generate answers using multi-threading"""
    qa_pairs = {}
    if message is None:
        message = []
    def _generate_answer(item):
        """Inner function for answer generation"""
        prompt = get_system_prompt_for_answer(item["page"], item["question"])
        answer = llm_generator(
            api_key=api_key,
            model=model,
            base_url=base_url,
            prompt=prompt,
            message=message,
            type="answer",
        )
        return item["question"], answer

    logger.info(f"å¼€å§‹ç”Ÿæˆç­”æ¡ˆ (çº¿ç¨‹æ•°: {max_workers})...")
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = {
            executor.submit(_generate_answer, item): item for item in question_items
        }

        with tqdm(as_completed(futures), total=len(futures), desc="ç”Ÿæˆç­”æ¡ˆ") as pbar:
            for future in pbar:
                question, answer = future.result()
                if answer:
                    with lock:
                        qa_pairs[question] = answer
                    pbar.set_postfix({"å·²ç”Ÿæˆç­”æ¡ˆ": len(qa_pairs)})
    return qa_pairs


# find tagpath by label

def find_tagpath_by_label(domain_tree: DomainTree, label: str):
    return domain_tree.find_path(label)



def generatr_qa_pairs(
    question_info: list,
    api_key: str,
    base_url: str,
    model_name: str,
    question_number: int = 5,
    message: list = None,
    max_workers: int = 5,
    domain_tree: DomainTree = None,  
) -> list:
    if message is None:
        message = []
    if domain_tree is None:
        from datamax.utils.domain_tree import DomainTree
        domain_tree = DomainTree([])
    qa_pairs = process_answers(
        question_items=question_info,
        message=message,
        max_workers=max_workers,
        api_key=api_key,
        base_url=base_url,
        model=model_name,
    )
    logger.success(
        f"å®Œæˆ! å…±ç”Ÿæˆ {len(qa_pairs)} ä¸ªé—®ç­”å¯¹"
    )
    res_list = []
    for question_item in question_info:
        question = question_item["question"]
        label = question_item.get("label", "")
        answer = qa_pairs.get(question, "")
        tag_path = find_tagpath_by_label(domain_tree, label) if domain_tree else ""
        qid = question_item.get("qid", "")
        method = "text with tree label" if domain_tree else "text"
        qa_entry = {
            "qid": qid,
            "instruction": question,
            "input": "",
            "output": answer,
            "label": label,
            "tag-path": tag_path,
            "method": method
        }
        res_list.append(qa_entry)
    return res_list


def _interactive_tree_modification(domain_tree):
    """
    äº¤äº’å¼è‡ªå®šä¹‰é¢†åŸŸæ ‘ç»“æ„
    :param domain_tree: DomainTreeå®ä¾‹
    :return: ä¿®æ”¹åçš„DomainTreeå®ä¾‹
    """
    print("\n æ˜¯å¦éœ€è¦è¿›è¡Œæ ‘ä¿®æ”¹ï¼Ÿ")
    print("æ”¯æŒçš„æ“ä½œ:")
    print("1. å¢åŠ èŠ‚ç‚¹ï¼šxxxï¼›çˆ¶èŠ‚ç‚¹ï¼šxxx   ï¼ˆçˆ¶èŠ‚ç‚¹å¯ç•™ç©ºï¼Œç•™ç©ºåˆ™æ·»åŠ ä¸ºæ ¹èŠ‚ç‚¹ï¼‰")
    print("2. å¢åŠ èŠ‚ç‚¹ï¼šxxxï¼›çˆ¶èŠ‚ç‚¹ï¼šxxxï¼›å­èŠ‚ç‚¹ï¼šxxx")
    print("3. åˆ é™¤èŠ‚ç‚¹ï¼šxxx")
    print("4. æ›´æ–°èŠ‚ç‚¹ï¼šæ–°åç§°ï¼›åŸå…ˆèŠ‚ç‚¹ï¼šæ—§åç§°")
    print("5. ç»“æŸæ ‘æ“ä½œ")
    print("æ³¨æ„ï¼ŒèŠ‚ç‚¹çš„æ ¼å¼é€šå¸¸ä¸ºï¼šx.xx xxxx,å¦‚ï¼šâ€˜1.1 è´§ç‰©è¿è¾“ç»„ç»‡ä¸è·¯å¾„è§„åˆ’â€™æˆ–â€˜1 è¿è¾“ç³»ç»Ÿç»„ç»‡â€™")
    print("\nè¯·è¾“å…¥æ“ä½œæŒ‡ä»¤ï¼ˆè¾“å…¥'ç»“æŸæ ‘æ“ä½œ'é€€å‡ºï¼‰:")
    while True:
        try:
            user_input = input("> ").strip()
            if user_input == "ç»“æŸæ ‘æ“ä½œ":
                print("âœ… æ ‘æ“ä½œç»“æŸï¼Œç»§ç»­QAå¯¹ç”Ÿæˆ...")
                break
            elif user_input.startswith("å¢åŠ èŠ‚ç‚¹ï¼š"):
                parts = user_input.split("ï¼›")
                if len(parts) >= 2:
                    node_name = parts[0].replace("å¢åŠ èŠ‚ç‚¹ï¼š", "").strip()
                    parent_name = parts[1].replace("çˆ¶èŠ‚ç‚¹ï¼š", "").strip()
                    if not parent_name:
                        if domain_tree.add_node(node_name):
                            print(f"âœ… æˆåŠŸå°†èŠ‚ç‚¹ '{node_name}' ä½œä¸ºæ ¹èŠ‚ç‚¹æ·»åŠ ")
                        else:
                            print(f"âŒ æ·»åŠ å¤±è´¥ï¼šæœªçŸ¥é”™è¯¯")
                    elif len(parts) == 2:
                        if domain_tree.add_node(node_name, parent_name):
                            print(f"âœ… æˆåŠŸæ·»åŠ èŠ‚ç‚¹ '{node_name}' åˆ°çˆ¶èŠ‚ç‚¹ '{parent_name}' ä¸‹")
                        else:
                            print(f"âŒ æ·»åŠ å¤±è´¥ï¼šæœªæ‰¾åˆ°çˆ¶èŠ‚ç‚¹ '{parent_name}'")
                    elif len(parts) == 3:
                        child_name = parts[2].replace("å­èŠ‚ç‚¹ï¼š", "").strip()
                        if domain_tree.insert_node_between(node_name, parent_name, child_name):
                            print(f"âœ… æˆåŠŸæ’å…¥èŠ‚ç‚¹ '{node_name}' åˆ° '{parent_name}' å’Œ '{child_name}' ä¹‹é—´")
                        else:
                            print(f"âŒ æ’å…¥å¤±è´¥ï¼šè¯·æ£€æŸ¥çˆ¶èŠ‚ç‚¹å’Œå­èŠ‚ç‚¹çš„å…³ç³»")
                    else:
                        print("âŒ æ ¼å¼é”™è¯¯ï¼šè¯·ä½¿ç”¨æ­£ç¡®çš„æ ¼å¼")
                else:
                    print("âŒ æ ¼å¼é”™è¯¯ï¼šè¯·ä½¿ç”¨æ­£ç¡®çš„æ ¼å¼")
            elif user_input.startswith("åˆ é™¤èŠ‚ç‚¹ï¼š"):
                node_name = user_input.replace("åˆ é™¤èŠ‚ç‚¹ï¼š", "").strip()
                if domain_tree.remove_node(node_name):
                    print(f"âœ… æˆåŠŸåˆ é™¤èŠ‚ç‚¹ '{node_name}' åŠå…¶æ‰€æœ‰å­å­™èŠ‚ç‚¹")
                else:
                    print(f"âŒ åˆ é™¤å¤±è´¥ï¼šæœªæ‰¾åˆ°èŠ‚ç‚¹ '{node_name}'")
            elif user_input.startswith("æ›´æ–°èŠ‚ç‚¹ï¼š"):
                parts = user_input.split("ï¼›")
                if len(parts) == 2:
                    new_name = parts[0].replace("æ›´æ–°èŠ‚ç‚¹ï¼š", "").strip()
                    old_name = parts[1].replace("åŸå…ˆèŠ‚ç‚¹ï¼š", "").strip()
                    if domain_tree.update_node(old_name, new_name):
                        print(f"âœ… æˆåŠŸå°†èŠ‚ç‚¹ '{old_name}' æ›´æ–°ä¸º '{new_name}'")
                    else:
                        print(f"âŒ æ›´æ–°å¤±è´¥ï¼šæœªæ‰¾åˆ°èŠ‚ç‚¹ '{old_name}'")
                else:
                    print("âŒ æ ¼å¼é”™è¯¯ï¼šè¯·ä½¿ç”¨æ­£ç¡®çš„æ ¼å¼ï¼Œå¦‚ï¼šæ›´æ–°èŠ‚ç‚¹ï¼šæ–°åç§°ï¼›åŸå…ˆèŠ‚ç‚¹ï¼šæ—§åç§°")
            else:
                print("âŒ æœªçŸ¥æ“ä½œï¼Œè¯·ä½¿ç”¨æ­£ç¡®çš„æ ¼å¼")
            print("\nğŸ“ å½“å‰æ ‘ç»“æ„:")
            print(domain_tree.visualize())
            print("\nè¯·è¾“å…¥ä¸‹ä¸€ä¸ªæ“ä½œæŒ‡ä»¤:")
            print("æ”¯æŒçš„æ“ä½œ:")
            print("1. å¢åŠ èŠ‚ç‚¹ï¼šxxxï¼›çˆ¶èŠ‚ç‚¹ï¼šxxx   ï¼ˆçˆ¶èŠ‚ç‚¹å¯ç•™ç©ºï¼Œç•™ç©ºåˆ™æ·»åŠ ä¸ºæ ¹èŠ‚ç‚¹ï¼‰")
            print("2. å¢åŠ èŠ‚ç‚¹ï¼šxxxï¼›çˆ¶èŠ‚ç‚¹ï¼šxxxï¼›å­èŠ‚ç‚¹ï¼šxxx")
            print("3. åˆ é™¤èŠ‚ç‚¹ï¼šxxx")
            print("4. æ›´æ–°èŠ‚ç‚¹ï¼šæ–°åç§°ï¼›åŸå…ˆèŠ‚ç‚¹ï¼šæ—§åç§°")
            print("5. ç»“æŸæ ‘æ“ä½œ")
            print("æ³¨æ„ï¼ŒèŠ‚ç‚¹çš„æ ¼å¼é€šå¸¸ä¸ºï¼šx.xx xxxx,å¦‚ï¼šâ€˜1.1 è´§ç‰©è¿è¾“ç»„ç»‡ä¸è·¯å¾„è§„åˆ’â€™æˆ–â€˜1 è¿è¾“ç³»ç»Ÿç»„ç»‡â€™")
        except KeyboardInterrupt:
            print("\n\nâš ï¸âš ï¸æ“ä½œè¢«ä¸­æ–­âš ï¸âš ï¸ï¼Œç»§ç»­QAå¯¹ç”Ÿæˆ...")
            break
        except Exception as e:
            print(f"âŒ æ“ä½œå‡ºé”™ï¼š{e}")
            print("è¯·é‡æ–°è¾“å…¥æ“ä½œæŒ‡ä»¤:")
    return domain_tree


def full_qa_labeling_process(
    content: str,
    api_key: str,
    base_url: str,
    model_name: str,
    chunk_size: int = 500,
    chunk_overlap: int = 100,
    question_number: int = 5,
    max_workers: int = 5,
    use_tree_label: bool = True,
    messages: list = None,
    interactive_tree: bool = True,
):
    """
    å°è£…å®Œæ•´çš„QAç”Ÿæˆæµç¨‹ï¼ŒåŒ…æ‹¬åˆ†å‰²ã€é¢†åŸŸæ ‘ç”Ÿæˆä¸äº¤äº’ã€é—®é¢˜ç”Ÿæˆã€æ ‡ç­¾æ‰“æ ‡ã€ç­”æ¡ˆç”Ÿæˆã€‚
    """
    from datamax.utils.qa_generator import (
        process_domain_tree,
        process_questions,
        process_match_tags,
        generatr_qa_pairs
    )
    import uuid

    # 1. åˆ†å‰²å†…å®¹
    from langchain.text_splitter import RecursiveCharacterTextSplitter
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size,
        chunk_overlap=chunk_overlap,
        length_function=len,
        is_separator_regex=False,
    )
    page_content = splitter.split_text(content)
    # 2. ç”Ÿæˆé¢†åŸŸæ ‘ï¼ˆå¯é€‰ï¼‰
    domain_tree = None
    if use_tree_label:
        from datamax.utils.domain_tree import DomainTree
        domain_tree = process_domain_tree(
            api_key=api_key,
            base_url=base_url,
            model=model_name,
            text="\n".join(page_content),
            temperature=0.7,
            top_p=0.9,
        )
        if interactive_tree and domain_tree and domain_tree.tree:
            print("\n" + "="*60)
            print("ğŸŒ³ ç”Ÿæˆçš„é¢†åŸŸæ ‘ç»“æ„:")
            print("="*60)
            print(domain_tree.visualize())
            print("="*60)
            domain_tree = _interactive_tree_modification(domain_tree)
    #ç”Ÿæˆé—®é¢˜
    question_info = process_questions(
        api_key=api_key,
        model=model_name,
        base_url=base_url,
        page_content=page_content,
        question_number=question_number,
        max_workers=max_workers,
        message=messages,
    )
    for question_item in question_info:
        if "qid" not in question_item:
            question_item["qid"] = str(uuid.uuid4())
    # 4. æ ‡ç­¾æ‰“æ ‡ï¼ˆå¯é€‰ï¼‰
    if use_tree_label and domain_tree and hasattr(domain_tree, 'to_json') and domain_tree.to_json():
        q_match_list = process_match_tags(
            api_key=api_key,
            base_url=base_url,
            model=model_name,
            tags_json=domain_tree.to_json(),
            questions=[q["question"] for q in question_info],
            max_workers=max_workers
        )
        label_map = {item["question"]: item.get("label", "") for item in q_match_list}
        for question_item in question_info:
            question_item["label"] = label_map.get(question_item["question"], "")
    else:
        for question_item in question_info:
            question_item["label"] = ""
    # 5. ç”Ÿæˆç­”æ¡ˆ
    qa_list = generatr_qa_pairs(
        question_info=question_info,
        api_key=api_key,
        base_url=base_url,
        model_name=model_name,
        question_number=question_number,
        max_workers=max_workers,
        domain_tree=domain_tree if use_tree_label else None
    )
    return qa_list


if __name__ == "__main__":
    # split text into chunks
    page_content = load_and_split_markdown(
        md_path="çŸ¥è¯†å›¾è°±.md",  
        chunk_size=500,
        chunk_overlap=100,
    )

    # generate domain tree
    domain_tree = process_domain_tree(
        api_key=API_KEY,
        base_url=BASE_URL,
        model="qwen-plus",
        text=page_content,
        temperature=0.7,
        top_p=0.9,
    )

    # generate question_info containing chuck and questions
    # question_info is the largest question set, will be adjusted according to the modification of the domain tree
    question_info = process_questions(
        page_content=page_content,
        question_number=5,  
        max_workers=10,  
        api_key=API_KEY,
        base_url=BASE_URL,
        model="qwen-plus",
    )

    # add unique id to each question
    for question_item in question_info:
        question_item["qid"] = str(uuid.uuid4())

    if not question_info:
        logger.error("æœªèƒ½ç”Ÿæˆä»»ä½•é—®é¢˜ï¼Œè¯·æ£€æŸ¥è¾“å…¥æ–‡æ¡£å’ŒAPIè®¾ç½®")
        
    # check if domain_tree is empty
    if not domain_tree or not domain_tree.to_json():
        logger.info("é¢†åŸŸæ ‘ä¸ºç©º, æœªè¿›è¡Œæ‰“æ ‡")
    else:
        # use DomainTree instance to match label
        q_match_list = process_match_tags(
            api_key=API_KEY,
            base_url=BASE_URL,
            model="qwen-plus",
            tags_json=domain_tree.to_json(),
            questions= [question_item["question"] for question_item in question_info],
            max_workers=3
        )
        logger.info(f"é—®é¢˜åŒ¹é…æ ‡ç­¾å®Œæˆ, ç»“æœæ˜¯: {q_match_list}")
        # merge label to question_info
        label_map = {item["question"]: item.get("label", "") for item in q_match_list}
        for question_item in question_info:
            question_item["label"] = label_map.get(question_item["question"], "")
        # get filtered question_info
        question_list = [question_item["question"] for question_item in question_info]
        question_info = [{"question": question_item["question"], "page": question_item["page"], "qid": question_item["qid"], "label": question_item["label"]} for question_item in question_info if question_item["question"] in question_list]

    # final answer
    r = generatr_qa_pairs(
        question_info=question_info,
        api_key=API_KEY,
        base_url=BASE_URL,
        model_name="qwen-plus",
        question_number=5,  
        max_workers=10,  
        domain_tree=domain_tree
        # message=[] 
    )

    print(r)
